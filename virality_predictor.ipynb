{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Charles Patel <br>\n",
    "Email: charlespatel007@yahoo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from typing import Dict, List\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('data/shared_articles.csv')\n",
    "interactions = pd.read_csv('data/users_interactions.csv')\n",
    "articles_info = pd.read_csv('data/article_info.csv') # features extracted from article text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated features from each article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.merge(left=articles, \n",
    "                        right=articles_info, \n",
    "                        left_on='contentId', \n",
    "                        right_on='contentId',\n",
    "                        how='left')\n",
    "article_data = article_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from user interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['activity_count'] = 1\n",
    "group_data = interactions.groupby(['contentId','eventType'])['activity_count'].sum().reset_index()\n",
    "activity_data = group_data.pivot_table('activity_count', ['contentId'], 'eventType').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_features = ['contentId', 'eventType', 'contentType', 'title', 'text', 'lang', 'tokens',\n",
    "                     'unique_tokens', 'average_token_length', 'n_non_stop_unique_tokens',\n",
    "                     'global_subjectivity', 'avg_positive_polarity', 'global_sentiment_polarity']\n",
    "\n",
    "data = pd.merge(left=activity_data, \n",
    "                right=article_data[articles_features], \n",
    "                left_on='contentId', \n",
    "                right_on='contentId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding to some featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_onehot = pd.get_dummies(data.eventType).replace({'CONTENT REMOVED': {1: -5}, 'CONTENT SHARED': {1: 5}})\n",
    "event_type_onehot.columns = ['CONTENT_REMOVED', 'CONTENT_SHARED']\n",
    "\n",
    "content_type_onehot = pd.get_dummies(data.contentType, prefix='CONTENT_TYPE')\n",
    "\n",
    "lang_onehot = pd.get_dummies(data.lang)\n",
    "lang_onehot.columns = ['LANGUAGE_EN', 'LANGUAGE_ES', 'LANGUAGE_JA', 'LANGUAGE_LA', 'LANGUAGE_PT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['eventType','contentType', 'lang'], axis=1)\n",
    "data = pd.concat([data, event_type_onehot, content_type_onehot, lang_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating lables (Virality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIRALITY = {\n",
    "    'VIEW': 1.0,\n",
    "    'LIKE': 4.0, \n",
    "    'COMMENT CREATED': 10.0,\n",
    "    'FOLLOW': 25.0,\n",
    "    'BOOKMARK': 100.0\n",
    "}\n",
    "\n",
    "def create_virality_label(row):\n",
    "    virality = 0\n",
    "    for activity, value in VIRALITY.items():\n",
    "        virality += value*row[activity]\n",
    "\n",
    "    virality += row['CONTENT_REMOVED']\n",
    "    virality += row['CONTENT_SHARED']\n",
    "    return virality\n",
    "\n",
    "data['VIRALITY'] = data.apply(lambda row: create_virality_label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['contentId', 'title', 'text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data.columns)\n",
    "\n",
    "X = data[features[:-1]]\n",
    "y = data[features[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(data.corr(), annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores, mae_scores, rmse_scores = dict(), dict(), dict()\n",
    "\n",
    "def calculate_scores(regressor_name: str, predicted: List, actual: List):\n",
    "    \"\"\"Calculate and store RMSE, MAE and R2 score from prediction\"\"\"\n",
    "    \n",
    "    r2_scores[regressor_name] = r2_score(actual, predicted)\n",
    "    mae_scores[regressor_name] = mean_absolute_error(actual, predicted)\n",
    "    rmse_scores[regressor_name] = mean_squared_error(actual, predicted, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "\n",
    "prediction_lr = linear_regression.predict(X_test)\n",
    "\n",
    "calculate_scores('linear_regression', prediction_lr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "prediction_lasso = lasso.predict(X_test)\n",
    "\n",
    "calculate_scores('lasso', prediction_lasso, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regression = RidgeCV(alphas = [0.001,0.1,1,5,10,100], \n",
    "                           scoring = 'neg_root_mean_squared_error', \n",
    "                           cv = None, \n",
    "                           store_cv_values = True)\n",
    "ridge_regression.fit(X_train, y_train)\n",
    "prediction_rr = ridge_regression.predict(X_test)\n",
    "\n",
    "calculate_scores('ridge_regression', prediction_rr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regression = XGBRegressor(random_state = 42)\n",
    "params_xgb = {'max_depth': [5,20,50]}\n",
    "gsc_xgb = GridSearchCV(estimator = xgb_regression, param_grid=params_xgb, cv=3, scoring='neg_root_mean_squared_error')\n",
    "gsc_xgb_res = gsc_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regression.max_depth = gsc_xgb_res.best_params_['max_depth']\n",
    "boosters = ['gbtree','gblinear']\n",
    "\n",
    "for booster_ in boosters:\n",
    "    xgb_regression.booster = booster_\n",
    "    xgb_regression.fit(X_train, y_train)\n",
    "\n",
    "    prediction_xgb = xgb_regression.predict(X_test)\n",
    "    calculate_scores('xgb_'+ booster_, prediction_xgb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost = CatBoostRegressor(verbose=0, random_state=42, eval_metric='RMSE')\n",
    "cat_boost.fit(X_train, y_train)\n",
    "prediction_cb = cat_boost.predict(X_test)\n",
    "\n",
    "calculate_scores('cat_boost', prediction_cb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_graph(name: str, data: Dict) -> None:\n",
    "    \"\"\"Plot bar-graph between model and its metric score\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(13,8))\n",
    "    ax = sns.barplot(x=list(data.keys()), y=list(data.values()), palette=\"Blues_d\")\n",
    "    ax.set_xlabel('Regressor Name')\n",
    "    ax.set_ylabel(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graph('RMSE', rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE (Mean Absolute Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graph('MAE', mae_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 (R - Squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_graph('R2', r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "```Linear regression``` with lowest ```RMSE``` and ```MAE``` performs well as compared to others and then Ridge and Lasso regression.<br>\n",
    "Thus, simple model can also performs well as compared to more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
